{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code to run in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a researcher submits his/her grant application, he also informs to grant agency his/her choice of discipline. This choice is not always accurate and could play a decisive role in receiving of the grant. The automatic classification of applications to suitable disciplines is possible by creating a classification model based on summaries of the applications, as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference I used for Tutorial: Keith Galli - Natural Language Processing (NLP) in Python - From Zero to Hero\n",
    "https://www.youtube.com/watch?v=vyOgWhwUmec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oia7bNPbVnq8"
   },
   "outputs": [],
   "source": [
    "#using spaCy pipelines for pretrained BERT\n",
    "!pip install spacy-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQDOd_0oX0N7"
   },
   "outputs": [],
   "source": [
    "#Using spacy NLP model\n",
    "!python -m spacy download en_trf_bertbaseuncased_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOe7SGALYj_Q"
   },
   "outputs": [],
   "source": [
    "#importing useful modules\n",
    "import spacy\n",
    "import torch #for deep learning\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The development of classification model needs data to train on and data to test. The following steps are taken to develop a model by using training data (summary and discipline per application) of a given grant round and then applying the model on the test data (summary and discipline per application) of the same grant round. I usually do half (26000) of the grant applications for training and other half(26000) for the testing, but it depends also on the nummber of applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNK9YZhVZt8t"
   },
   "outputs": [],
   "source": [
    "#reading the application excel as a TRAINING data where there are following columns: application number, summary, disciplines (selected by applicant)\n",
    "#The excel needs tobe in your google drive in the contents folder\n",
    "df=pd.read_excel('/content/drive/My Drive/train_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7pZ_cxsZuKp"
   },
   "outputs": [],
   "source": [
    "#dropping the nan values \n",
    "df = df[df['summary'].notna()]\n",
    "#conversion of columns to lists\n",
    "train_x=df['summary'].to_list()\n",
    "train_y=df['discipline'].to_list()\n",
    "#Converting vector values into string values\n",
    "train_x = [str (item) for item in train_x]\n",
    "train_y = [str (item) for item in train_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSycLgb8ZJrk"
   },
   "outputs": [],
   "source": [
    "#loading the spacy model (Check https://spacy.io/models)\n",
    "nlp = spacy.load('en_trf_bertbaseuncased_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYvez8BJcEb4"
   },
   "outputs": [],
   "source": [
    "#using NLP engine on the summary of the grant applications\n",
    "docs=[nlp(text) for text in train_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_T0WSvfcJHI"
   },
   "outputs": [],
   "source": [
    "#developing word vectors\n",
    "train_x_word_vectors=[x.vector for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "OsyhzR7KcMKx",
    "outputId": "1fd973ef-00bc-4fac-9362-5eb0761bb057"
   },
   "outputs": [],
   "source": [
    "#uses support vector classifier for fit\n",
    "from sklearn import svm\n",
    "#, datasets\n",
    "#C = 1.0  # SVM regularization parameter\n",
    "#clf_svm_wv=svm.SVC(kernel='rbf', gamma=0.7, C=C) #you can play here little bit to get better results\n",
    "clf_svm_wv=svm.SVC(kernel='linear')\n",
    "clf_svm_wv.fit(train_x_word_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNC8kSrEdplS"
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_excel('/content/drive/My Drive/test_data.xlsx')\n",
    "#dropping the nan values from summary \n",
    "df_test = df_test[df_test['summary'].notna()]\n",
    "#conversion of columns to lists\n",
    "test_x=df_test['summary'].to_list()\n",
    "#Converting vector values into string values\n",
    "test_x = [str (item) for item in test_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rlHAMDnscNj0"
   },
   "outputs": [],
   "source": [
    "#applying steps used before for test data hereunder\n",
    "test_docs=[nlp(text) for text in test_x]\n",
    "test_x_word_vectors=[x.vector for x in test_docs]\n",
    "#prediction by the word vector model for the summaries in the test data\n",
    "output_wordvector=clf_svm_wv.predict(test_x_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kbvo7LHFcYiW"
   },
   "outputs": [],
   "source": [
    "#creation of a summary dataframe to check whether the wordvector model can predict the disciplines of the grant applications\n",
    "#A dataframe is created here to compare the prediction by the word vector model and actual discipline given by the applicant\n",
    "df_summary = pd.DataFrame(columns = ['Application number', 'given_disci', 'wordvector_disci'])\n",
    "df_summary['Application number']=df_test['Application number']\n",
    "df_summary['given_disci']=df_test['discipline']\n",
    "df_summary['wordvector_disci']=output_wordvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ghSMWy9Ildf-",
    "outputId": "4608b403-8920-456a-c048-c3f1403e97ff"
   },
   "outputs": [],
   "source": [
    "#Quick check if how many good results were there\n",
    "total=0\n",
    "correct=0\n",
    "wrong=0\n",
    "i=0\n",
    "while i < len(df_summary):\n",
    "    if (df_summary.iloc[i,1]==df_summary.iloc[i,2]):\n",
    "        correct=correct+1\n",
    "    else:\n",
    "        wrong=wrong+1\n",
    "    i=i+1\n",
    "print(\"total \" + str(total))\n",
    "print(\"correct \"+ str(correct))\n",
    "print(\"wrong \"+ str(wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TadISDdKAamB",
    "outputId": "eba7a044-189f-4f1a-d3bc-a028ddefaa87"
   },
   "outputs": [],
   "source": [
    "#saving the dataframe as an excel file\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Color, PatternFill, Font, Border\n",
    "from openpyxl.styles.differential import DifferentialStyle\n",
    "from openpyxl.formatting.rule import ColorScaleRule, CellIsRule, FormulaRule\n",
    "\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "\n",
    "ws.title='Discipline classification'\n",
    "\n",
    "for r in dataframe_to_rows(df_summary, index=False, header=True):\n",
    "    ws.append(r)\n",
    "\n",
    "red_text = Font(color=\"9C0006\")\n",
    "redFill = PatternFill(bgColor=\"FFC7CE\")\n",
    "ws.conditional_formatting.add('B2:C297', FormulaRule(formula=['$B2=$C2'], stopIfTrue=False, fill=redFill))\n",
    "    #saving the excel workbook\n",
    "Exportfile_name=input('Give export file name ',)# write the name of the file with extension .xlsx\n",
    "wb.save(Exportfile_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "spacey meets transformers Fine-tune BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
